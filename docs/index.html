<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="ToonTalker: Cross-Domain Face Reenactment">
  <meta property="og:title" content="ToonTalker: Cross-Domain Face Reenactment"/>
  <meta property="og:description" content="ToonTalker: Cross-Domain Face Reenactment"/>
  <meta property="og:url" content=""/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/carousel1.jpg" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="ToonTalker: Cross-Domain Face Reenactment">
  <meta name="twitter:description" content="ToonTalker: Cross-Domain Face Reenactment">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/carousel1.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ToonTalker</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h4 class="title publication-title">
              ToonTalker: Cross-Domain Face Reenactment
            </h4>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="#" target="_blank">Yuan Gong</a><sup>1</sup>
              </span>
              <span class="author-block">
                <a href="https://yzhang2016.github.io/" target="_blank">Yong Zhang</a><sup>2, *</sup>
              </span>
              <span class="author-block">
                <a href="https://vinthony.github.io/academic/" target="_blank">Xiaodong Cun</a><sup>2</sup>
              </span>
              <span class="author-block">
                <a href="https://github.com/FeiiYin" target="_blank">Fei Yin</a><sup>1</sup>
              </span>
              <span class="author-block">
                <a href="" target="_blank">Yanbo Fan</a><sup>2</sup>
              </span>
              <span class="author-block">
                <a href="https://xuanwangvc.github.io/" target="_blank">Xuan Wang</a><sup>3</sup>
              </span>
              <span class="author-block">
                <a href="https://sds.cuhk.edu.cn/en/teacher/322" target="_blank">Baoyuan Wu</a><sup>4</sup>
              </span>
              <span class="author-block">
                <a href="https://sites.google.com/view/iigroup-thu/home" target="_blank">Yujiu Yang</a><sup>1, *</sup>
              </span>
            </div>
                  <br>
                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup> Tsinghua University &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                      <sup>2</sup> Tencent AI Lab &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                      <sup>3</sup> Ant Group &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                      <sup>4</sup> The School of Data Science, Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen)<br>
                      <sup>*</sup> Corresponding Authors
                  </div>
                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2308.12866" target="_blank"
                        class="external-link is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/yuanygong/ToonTalker" target="_blank"
                    class="external-link is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
<!-- 
                <span class="link-block">
                  <a href="" target="_blank"
                  class="external-link is-normal is-rounded is-dark">
                  <span>ðŸ¤— Demo (Hugging Face Space)</span>
                </a>
              </span>

              <span class="link-block">
                  <a href="" target="_blank"
                  class="external-link is-normal is-rounded is-dark">
                  <span>ðŸ§¿ Demo (Colab)</span>
                </a>
              </span> -->

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- End paper abstract -->

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <!-- <h2 class="title is-3">Pipeline</h2> -->
    <div class="l-article">
      <img src="docs/static/videos/teaser.mp4" width="100%">
    </div>
    <!-- <div class="l-article">
      <img src="./static/images/pipeline.jpg" width="100%">
    </div> -->
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3"><strong>Abstract</h2>
      <div class="video"  style="text-align:center">
    </div>
    <div class="content has-text-justified">
      <p style="font-size: 14px;">
        We target cross-domain face reenactment in this paper, i.e., driving a cartoon image with the video of a real person and vice versa. 
        Recently, many works have focused on one-shot talking face generation to drive a portrait with a real video, i.e., within-domain reenactment. 
        Straightforwardly applying those methods to cross-domain animation will cause inaccurate expression transfer, blur effects, and even apparent artifacts due to the domain shift between cartoon and real faces. 
        Only a few works attempt to settle cross-domain face reenactment. 
        The most related work AnimeCeleb requires constructing a dataset with pose vector and cartoon image pairs by animating 3D characters, which makes it inapplicable anymore if no paired data is available. 
        In this paper, we propose a novel method for cross-domain reenactment without paired data. 
        Specifically, we propose a transformer-based framework to align the motions from different domains into a common latent space where motion transfer is conducted via latent code addition. 
        Two domain-specific motion encoders and two learnable motion base memories are used to capture domain properties. 
        A source query transformer and a driving one are exploited to project domain-specific motion to the canonical space. 
        The edited motion is projected back to the domain of the source with a transformer. 
        Moreover, since no paired data is provided, we propose a novel cross-domain training scheme using data from two domains with the designed analogy constraint. 
        Besides, we contribute a cartoon dataset in Disney style. 
        Extensive evaluations demonstrate the superiority of our method over competing methods.
      </p>
    </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3"><strong>Pipeline</h2>
        <div class="l-article">
          <img src="./static/images/pipeline.png" width="100%">
        </div>
    </div>
  </div>
</section>

<!-- aper abstract
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Accurate Story visualization requires several necessary elements, such as identity consistency across frames, the alignment between plain text and visual content, and a reasonable layout of objects in images. 
            Most previous works endeavor to meet these requirements by fitting a text-to-image (T2I) model on a set of videos in the same style and with the same characters, e.g., the FlintstonesSV dataset. 
            However, the learned T2I models typically struggle to adapt to new characters, scenes, and styles, and often lack the flexibility to revise the layout of the synthesized images.
            This paper proposes a system for generic interactive story visualization, capable of handling multiple novel characters and supporting the editing of layout and local structure. 
            It is developed by leveraging the prior knowledge of large language and T2I models, trained on massive corpora. 
            The system comprises four interconnected components: story-to-prompt generation (S2P), text-to-layout generation (T2L), controllable text-to-image generation (C-T2I), and image-to-video animation (I2V). 
            First, the S2P module converts concise story information into detailed prompts required for subsequent stages. 
            Next, T2L generates diverse and reasonable layouts based on the prompts, offering users the ability to adjust and refine the layout to their preference. 
            The core component, C-T2I, enables the creation of images guided by layouts, sketches, and actor-specific identifiers to maintain consistency and detail across visualizations. 
            Finally, I2V enriches the visualization process by animating the generated images.
            Extensive experiments and a user study are conducted to validate the effectiveness and flexibility of interactive editing of the proposed system.
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->

<section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <!-- Paper video. -->
        <h2 class="title is-3"><strong>Video</strong></h2>
        <div class="video">
          <!--    <div class="l-page video">-->
          <video controls="" loop="" width="80%">
              <!-- t=0.001 is a hack to make iPhone show video thumbnail -->
              <source src="static/videos/R2C1.mp4" type="video/mp4">
          </video>
          <video controls="" loop="" width="80%">
              <!-- t=0.001 is a hack to make iPhone show video thumbnail -->
              <source src="static/videos/R2C2.mp4" type="video/mp4">
          </video>
          <video controls="" loop="" width="80%">
              <!-- t=0.001 is a hack to make iPhone show video thumbnail -->
              <source src="static/videos/C2R_1.mp4" type="video/mp4">
          </video>
          <video controls="" loop="" width="80%">
              <!-- t=0.001 is a hack to make iPhone show video thumbnail -->
              <source src="static/videos/C2R_2.mp4" type="video/mp4">
          </video>
          <video controls="" loop="" width="80%">
              <!-- t=0.001 is a hack to make iPhone show video thumbnail -->
              <source src="static/videos/indomain1.mp4" type="video/mp4">
          </video>
          <video controls="" loop="" width="80%">
              <!-- t=0.001 is a hack to make iPhone show video thumbnail -->
              <source src="static/videos/indomain2.mp4" type="video/mp4">
          </video>
      </div>
      </div>
    </div>
  </section>

<!-- <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3"><strong>Video</strong>: Supplement</h2>
        <div class="video">
          <video controls="" loop="" width="100%">
              <source src="static/videos/demo.mp4" type="video/mp4">
          </video>
      </div>
      </div>
    </div>
  </section> -->




<!-- End teaser video -->

  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{pang2023dpe,
        title={DPE: Disentanglement of Pose and Expression for General Video Portrait Editing},
        author={Pang, Youxin and Zhang, Yong and Quan, Weize and Fan, Yanbo and Cun, Xiaodong and Shan, Ying and Yan, Dong-ming},
        journal={arXiv preprint arXiv:2301.06281},
        year={2023}
      }
</code></pre>
    </div>
</section> -->
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/vinthony/project-page-template">modification version</a> of <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> from <a href="https://github.com/vinthony">vinthony</a>.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br>
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
